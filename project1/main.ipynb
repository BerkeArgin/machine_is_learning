{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "\n",
    "from implementations import *\n",
    "from preprocess import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\n",
    "    \"categorical_vars\": [\n",
    "    \"SEX\",\n",
    "    \"_RFHLTH\",\n",
    "    \"_HCVU651\",\n",
    "    \"_RFHYPE5\",\n",
    "    \"_CHOLCHK\",\n",
    "    \"_RFCHOL\",\n",
    "    \"_MICHD\",\n",
    "    \"_LTASTH1\",\n",
    "    \"_CASTHM1\",\n",
    "    \"_ASTHMS1\",\n",
    "    \"_DRDXAR1\",\n",
    "    \"_PRACE1\",\n",
    "    \"_MRACE1\",\n",
    "    \"_M_RACE\",\n",
    "    \"_HISPANC\",\n",
    "    \"_RACE\",\n",
    "    \"_RACEG21\",\n",
    "    \"_RACEGR3\",\n",
    "    \"_RACE_G1\",\n",
    "    \"_AGEG5YR\",\n",
    "    \"_AGE_G\",\n",
    "    \"_BMI5CAT\",\n",
    "    \"_RFBMI5\",\n",
    "    \"_CHLDCNT\",\n",
    "    \"_INCOMG\",\n",
    "    \"_SMOKER3\",\n",
    "    \"_RFSMOK3\",\n",
    "    \"DRNKANY5\",\n",
    "    \"_RFDRHV5\",\n",
    "    \"_FRTLT1\",\n",
    "    \"_VEGLT1\",\n",
    "    \"_TOTINDA\",\n",
    "    \"ACTIN11_\",\n",
    "    \"ACTIN21_\",\n",
    "    \"_PACAT1\",\n",
    "\"_PAINDX1\",\n",
    "\"_PA150R2\",\n",
    "\"_PA300R2\",\n",
    "\"_PA30021\",\n",
    "\"_PASTRNG\",\n",
    "\"_PAREC1\",\n",
    "\"_LMTACT1\",\n",
    "\"_LMTWRK1\",\n",
    "\"_AIDTST3\"\n",
    "],\n",
    "    \"numerical_vars\":[\"AGE\", \"HTIN4\",\"HTM4\",\"WTKG3\",\"_BMI5\",\"_DRNKWEK\", \"FTJUDA1_\", \"GRENDAY_\",\"BEANDAY_\",\"FRUTDA1_\",\"ORNGDAY_\",\"VEGEDA1_\",\"PADUR1_\",\"PADUR2_\",\"_MINAC11\"]\n",
    "}\n",
    "    \n",
    "data_path=\"./data/dataset_to_release\"\n",
    "x_train, x_test, y_train, train_ids, test_ids, selected_indices_categorical_train = load_csv_data(data_path, selected_cols=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_undersampled_train, y_undersampled_train = undersample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected NaNs in column 5. Imputing with value 2.0.\n",
      "Detected NaNs in column 9. Imputing with value 2.0.\n",
      "Detected NaNs in column 16. Imputing with value 1.0.\n",
      "Detected NaNs in column 19. Imputing with value 3.0.\n",
      "Detected NaNs in column 37. Imputing with value 3.0.\n",
      "Detected NaNs in column 38. Imputing with value 3.0.\n",
      "Detected NaNs in column 39. Imputing with value 2.0.\n",
      "Detected NaNs in column 40. Imputing with value 66.0.\n",
      "Detected NaNs in column 41. Imputing with value 1.68.\n",
      "Detected NaNs in column 42. Imputing with value 90.72.\n",
      "Detected NaNs in column 43. Imputing with value 26.63.\n",
      "Detected NaNs in column 45. Imputing with value 0.0.\n",
      "Detected NaNs in column 46. Imputing with value 1.0.\n",
      "Detected NaNs in column 47. Imputing with value 0.0.\n",
      "Detected NaNs in column 48. Imputing with value 1.0.\n",
      "Detected NaNs in column 49. Imputing with value 0.0.\n",
      "Detected NaNs in column 50. Imputing with value 1.0.\n",
      "Detected NaNs in column 5. Imputing with value 1.0.\n",
      "Detected NaNs in column 9. Imputing with value 2.0.\n",
      "Detected NaNs in column 16. Imputing with value 1.0.\n",
      "Detected NaNs in column 19. Imputing with value 3.0.\n",
      "Detected NaNs in column 37. Imputing with value 3.0.\n",
      "Detected NaNs in column 38. Imputing with value 3.0.\n",
      "Detected NaNs in column 39. Imputing with value 2.0.\n",
      "Detected NaNs in column 40. Imputing with value 66.0.\n",
      "Detected NaNs in column 41. Imputing with value 1.68.\n",
      "Detected NaNs in column 42. Imputing with value 90.72.\n",
      "Detected NaNs in column 43. Imputing with value 26.63.\n",
      "Detected NaNs in column 45. Imputing with value 0.0.\n",
      "Detected NaNs in column 46. Imputing with value 1.0.\n",
      "Detected NaNs in column 47. Imputing with value 0.0.\n",
      "Detected NaNs in column 48. Imputing with value 1.0.\n",
      "Detected NaNs in column 49. Imputing with value 0.0.\n",
      "Detected NaNs in column 50. Imputing with value 1.0.\n"
     ]
    }
   ],
   "source": [
    "all_categories = [np.unique(x_undersampled_train[:, idx][~np.isnan(x_undersampled_train[:, idx])]) for idx in selected_indices_categorical_train]\n",
    "\n",
    "full_data_preprocessed, _ = apply_preprocessing(x_undersampled_train, x_test, selected_indices_categorical_train, all_categories)\n",
    "if np.isnan(full_data_preprocessed).any():\n",
    "    print(\"NaNs introduced during preprocessing on the full dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_undersampled_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 299160, 1: 28975}\n",
      "{-1: 28975, 1: 28975}\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the _MICHD labels\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)\n",
    "\n",
    "unique, counts = np.unique(y_undersampled_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_undersampled_train, dropped_train_cols = drop_high_nan_columns(x_undersampled_train)\n",
    "x_test = np.delete(x_test, dropped_train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_undersampled_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute precision, recall, accuracy, and F1 score.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: List of true labels\n",
    "    - y_pred: List of predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with precision, recall, accuracy, and F1 score\n",
    "    \"\"\"\n",
    "    TP = sum([1 for yt, yp in zip(y_true, y_pred) if yt == 1 and yp == 1])\n",
    "    FP = sum([1 for yt, yp in zip(y_true, y_pred) if yt == -1 and yp == 1])\n",
    "    FN = sum([1 for yt, yp in zip(y_true, y_pred) if yt == 1 and yp == -1])\n",
    "    TN = sum([1 for yt, yp in zip(y_true, y_pred) if yt == -1 and yp == -1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_val = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall_val = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    accuracy_val = (TP + TN) / len(y_true)\n",
    "    f1_val = 2 * (precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) != 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"Precision\": precision_val,\n",
    "        \"Recall\": recall_val,\n",
    "        \"Accuracy\": accuracy_val,\n",
    "        \"F1 Score\": f1_val\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stratified_k_indices_with_seed(y, k_fold, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly partitions the indices of the dataset into k groups in a stratified manner using a fixed seed.\n",
    "    Args:\n",
    "        y: labels, used for indexing\n",
    "        k_fold: number of groups after the partitioning\n",
    "        seed: the random seed value, default is 42\n",
    "    Returns:\n",
    "        k_indices: an array of k sub-indices that are stratified partitioned\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Get unique classes and their counts\n",
    "    classes, class_counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Calculate how many samples of each class should be in each fold\n",
    "    n_samples_per_class_per_fold = (class_counts / k_fold).astype(int)\n",
    "    n_samples_remaining = class_counts % k_fold\n",
    "\n",
    "    # Distribute samples for each class to the folds\n",
    "    k_indices = [[] for _ in range(k_fold)]\n",
    "    \n",
    "    for c in classes:\n",
    "        class_indices = np.where(y == c)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "        \n",
    "        fold_counts = n_samples_per_class_per_fold[c] * np.ones(k_fold, dtype=int)\n",
    "        fold_counts[:n_samples_remaining[c]] += 1  # Distribute the remaining samples\n",
    "        \n",
    "        current = 0\n",
    "        for k in range(k_fold):\n",
    "            start, stop = current, current + fold_counts[k]\n",
    "            k_indices[k].extend(class_indices[start:stop])\n",
    "            current = stop\n",
    "\n",
    "    # Convert each fold's indices to a numpy array\n",
    "    k_indices = [np.array(indices) for indices in k_indices]\n",
    "\n",
    "    return np.array(k_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_fold(y, x, k_indices, k, selected_indices_categorical_train, all_categories):\n",
    "    \"\"\"\n",
    "    Prepare the data for a given fold index.\n",
    "\n",
    "    Args:\n",
    "        y: Vector of labels\n",
    "        x: Feature matrix\n",
    "        k_indices: 2D array returned by build_k_indices()\n",
    "        k: scalar, the k-th fold\n",
    "        degree: Degree for polynomial expansion\n",
    "        high_skewness_cols: Columns that need log transform\n",
    "        high_residual_indices: Columns that need polynomial expansion\n",
    "\n",
    "    Returns:\n",
    "        train_x, train_y, test_x, test_y: Prepared data for the fold\n",
    "    \"\"\"\n",
    "    \n",
    "    test_x, test_y = x[k_indices[k]], y[k_indices[k]]\n",
    "    train_x, train_y = (\n",
    "        x[k_indices[(np.arange(len(k_indices)) != k)].reshape(-1)],\n",
    "        y[k_indices[(np.arange(len(k_indices)) != k)].reshape(-1)],\n",
    "    )\n",
    "    \n",
    "    #print(f\"Shape of train_x before preprocessing: {train_x.shape}\")\n",
    "    #print(f\"Shape of test_x before preprocessing: {test_x.shape}\")\n",
    "    \n",
    "    train_x, test_x = apply_preprocessing(train_x, test_x, selected_indices_categorical_train, all_categories)\n",
    "    #print(f\"Shape of train_x after preprocessing: {train_x.shape}\")\n",
    "    #print(f\"Shape of test_x after preprocessing: {test_x.shape}\")\n",
    "    if np.isnan(train_x).any():\n",
    "        print(f\"NaNs detected in train_x after initial k-fold splitting for fold {k}!\")\n",
    "    if np.isnan(test_x).any():\n",
    "        print(f\"NaNs detected in test_x after initial k-fold splitting for fold {k}!\")\n",
    "\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, weights, is_logistic):\n",
    "        preds = data.dot(weights)\n",
    "        if is_logistic:\n",
    "            preds = np.where(sigmoid(preds) > 0.5, 1, -1)\n",
    "        else:\n",
    "            preds = np.where(preds >= 0, 1, -1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_x, train_y, test_x, test_y, model_func, \n",
    "                       lambda_=0.1, max_iters=1000, gamma=0.01):\n",
    "    \"\"\"\n",
    "    Train a model and evaluate it. Now adapted for weighted training and flexible arguments.\n",
    "\n",
    "    Args:\n",
    "        train_x, train_y: Training data\n",
    "        test_x, test_y: Testing data\n",
    "        model_func: The regression function to use\n",
    "        weights: Sample weights\n",
    "        lambda_: Regularization parameter (if applicable)\n",
    "        max_iters: Maximum number of iterations for iterative optimization methods, default 1000.\n",
    "        gamma: Learning rate for optimization methods, default 0.01.\n",
    "\n",
    "    Returns:\n",
    "        Training and testing losses, accuracy, precision, recall, and F1 score\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_w = np.zeros(train_x.shape[1])\n",
    "    is_logistic = model_func in [logistic_regression, reg_logistic_regression]\n",
    "\n",
    "    unique, counts = np.unique(train_y, return_counts=True)\n",
    "    value_counts = dict(zip(unique, counts))\n",
    "    #print(value_counts)\n",
    "    print(\"***********************\")\n",
    "    train_y_adjusted = (train_y + 1) / 2 if is_logistic else train_y\n",
    "    \n",
    "    # --- DIAGNOSTIC CODE INSERTED --- #\n",
    "    \"\"\"\n",
    "    # 1. Check for NaNs in the train data\n",
    "    if np.any(np.isnan(train_x)):\n",
    "        print(\"Warning: NaN values detected in train_x!\")\n",
    "    \n",
    "    # 2. Check if features are scaled\n",
    "    feature_means = np.mean(train_x, axis=0)\n",
    "    feature_stds = np.std(train_x, axis=0)\n",
    "    print(f\"Feature Means: {feature_means}\")\n",
    "    print(f\"Feature Stds: {feature_stds}\")\n",
    "    \n",
    "    # 3. Check for constant features\n",
    "    constant_features = np.all(train_x == train_x[0, :], axis=0)\n",
    "    if np.any(constant_features):\n",
    "        print(f\"Warning: Constant features detected at indices {np.where(constant_features)}!\")\n",
    "    \n",
    "    # --- END OF DIAGNOSTIC CODE --- #\n",
    "    \"\"\"\n",
    "    # Train model based on selected function\n",
    "    if model_func in [mean_squared_error_gd, mean_squared_error_sgd, logistic_regression]:\n",
    "        w, loss_history = model_func(train_y_adjusted, train_x, initial_w, max_iters, gamma)\n",
    "    elif model_func in [reg_logistic_regression]:\n",
    "        w, loss_history = model_func(train_y_adjusted, train_x, lambda_, initial_w, max_iters, gamma)\n",
    "    elif model_func in [least_squares, ridge_regression]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, lambda_)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model selection\")\n",
    "    \n",
    "    # If you have a loss history, print its last few values\n",
    "    if 'loss_history' in locals() :\n",
    "        print(f\"loss value: {loss_history}\")\n",
    "        print(\"***********************\")\n",
    "\n",
    "    # Predict and compute metrics for training data\n",
    "    preds_train = predict(train_x, w, is_logistic)\n",
    "    loss_train = np.sqrt(np.mean((train_y_adjusted - preds_train)**2))\n",
    "    metrics_train = compute_metrics(train_y_adjusted, preds_train)\n",
    "    if np.unique(preds_train).size == 1 and (preds_train[0] == 1 or preds_train[0] == -1):\n",
    "        print(\"Warning: Model only assigns\", preds_train[0], \"to all training samples!\")\n",
    "\n",
    "    # Predict and compute metrics for testing data\n",
    "    preds_test = predict(test_x, w, is_logistic)\n",
    "    loss_test = np.sqrt(np.mean((test_y - preds_test)**2))\n",
    "    metrics_test = compute_metrics(test_y, preds_test)\n",
    "\n",
    "    if np.unique(preds_test).size == 1 and (preds_test[0] == 1 or preds_test[0] == -1):\n",
    "        print(\"Warning: Model only assigns\", preds_test[0], \"to all test samples!\")\n",
    "        \n",
    "    return {\n",
    "        \"loss_train\": loss_train,\n",
    "        \"loss_test\": loss_test,\n",
    "        \"metrics_train\": metrics_train,\n",
    "        \"metrics_test\": metrics_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_hyperparameters_weighted(y, x, k_indices, model_funcs, categorical_columns_indices):\n",
    "    \"\"\"Perform grid search with progress tracking.\"\"\"\n",
    "    gammas = [0.001, 0.01, 0.1]\n",
    "    lambdas = [0.001, 0.01, 0.1]\n",
    "    max_iters_values = [100, 500]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = None\n",
    "    best_model = None\n",
    "    all_categories = [np.unique(x[:, idx][~np.isnan(x[:, idx])]) for idx in categorical_columns_indices]\n",
    "\n",
    "    total_models = len(model_funcs)\n",
    "    for idx, model_func in enumerate(model_funcs):\n",
    "        print(f\"Evaluating Model {idx+1}/{total_models}: {model_func.__name__}\")\n",
    "        for gamma in gammas:\n",
    "            for lambda_ in lambdas:\n",
    "                for max_iters in max_iters_values:\n",
    "                    fold_accuracies = []\n",
    "                    fold_f1_scores = []\n",
    "                    fold_precision = []\n",
    "                    fold_recall = []\n",
    "                    for k in range(len(k_indices)):\n",
    "                        train_x, train_y, test_x, test_y = prepare_data_for_fold(y, x, k_indices, k, selected_indices_categorical_train, all_categories)\n",
    "                        \n",
    "                        if np.any(np.isnan(train_x)):\n",
    "                            print(\"Warning: NaN values detected in train_x! - althogh imputed pred\")\n",
    "                        results = train_and_evaluate(train_x, train_y, test_x, test_y, model_func, lambda_=lambda_, max_iters=max_iters, gamma=gamma)\n",
    "                        \n",
    "                        fold_accuracies.append(results[\"metrics_test\"][\"Accuracy\"])\n",
    "                        fold_f1_scores.append(results[\"metrics_test\"][\"F1 Score\"])\n",
    "                        fold_precision.append(results[\"metrics_test\"][\"Precision\"])\n",
    "                        fold_recall.append(results[\"metrics_test\"][\"Recall\"])\n",
    "                    \n",
    "                    average_accuracy = np.mean(fold_accuracies)\n",
    "                    average_f1 = np.mean(fold_f1_scores)\n",
    "                    average_precision = np.mean(fold_precision)\n",
    "                    average_recall = np.mean(fold_recall)\n",
    "                    \n",
    "                    print(f\"Gamma: {gamma}, Lambda: {lambda_}, Max Iters: {max_iters}\")\n",
    "                    print(f\"Average Accuracy: {average_accuracy:.4f}, Average F1: {average_f1:.4f}\")\n",
    "                    print(f\"Average Precision: {average_precision:.4f}, Average Recall: {average_recall:.4f}\")\n",
    "                    print(\"-------------------------------------------------------------\")\n",
    "\n",
    "                    # Update best hyperparameters if this combination gives better F1 score\n",
    "                    if average_f1 > best_f1:\n",
    "                        best_f1 = average_f1\n",
    "                        best_accuracy = average_accuracy\n",
    "                        best_hyperparameters = {\n",
    "                            \"gamma\": gamma,\n",
    "                            \"lambda_\": lambda_,\n",
    "                            \"max_iters\": max_iters\n",
    "                        }\n",
    "                        best_model = model_func.__name__\n",
    "\n",
    "    return best_model, best_hyperparameters, best_accuracy, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_best_model(x_train, y_train, x_test, best_model_func, best_hyperparameters):\n",
    "    \"\"\"\n",
    "    Train the best model using the entire training set and get predictions for the test set.\n",
    "    \n",
    "    Args:\n",
    "    - x_train: Training data features\n",
    "    - y_train: Training data labels\n",
    "    - x_test: Test data features\n",
    "    - best_model_func: The best model function obtained from grid search\n",
    "    - best_hyperparameters: Dictionary containing the best hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "    - preds_test: Predictions for the test data\n",
    "    \"\"\"\n",
    "    \n",
    "    is_logistic = best_model_func in [logistic_regression, reg_logistic_regression]\n",
    "    y_train_adjusted = (y_train + 1) / 2 if is_logistic else y_train\n",
    "    \n",
    "    initial_w = np.zeros(x_train.shape[1])\n",
    "    gamma = best_hyperparameters[\"gamma\"]\n",
    "    lambda_ = best_hyperparameters[\"lambda_\"]\n",
    "    max_iters = best_hyperparameters[\"max_iters\"]\n",
    "    \n",
    "    # Train model using the entire training data\n",
    "    if best_model_func in [mean_squared_error_gd, mean_squared_error_sgd, logistic_regression]:\n",
    "        w, _ = best_model_func(y_train_adjusted, x_train, initial_w, max_iters, gamma)\n",
    "    elif best_model_func in [reg_logistic_regression]:\n",
    "        w, _ = best_model_func(y_train_adjusted, x_train, lambda_, initial_w, max_iters, gamma)\n",
    "    elif best_model_func in [least_squares, ridge_regression]:\n",
    "        w, _ = best_model_func(y_train_adjusted, x_train, lambda_)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model selection\")\n",
    "    \n",
    "    # Predict for test data\n",
    "    preds_test = predict(x_test, w, is_logistic)\n",
    "    \n",
    "    return preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model 1/2: logistic_regression\n",
      "{-1: 23180, 1: 23180}\n",
      "***********************\n",
      "loss value: 37.112750549587986\n",
      "{-1: 23180, 1: 23180}\n",
      "***********************\n",
      "loss value: 37.600442409823486\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\main.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m k_indices \u001b[39m=\u001b[39m build_stratified_k_indices_with_seed(y_undersampled_train, k_fold, seed)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_funcs \u001b[39m=\u001b[39m [logistic_regression, reg_logistic_regression]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best_model, best_hyperparameters, best_accuracy, best_f1 \u001b[39m=\u001b[39m grid_search_hyperparameters_weighted(y_undersampled_train, x_undersampled_train,  k_indices, model_funcs, selected_indices_categorical_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, best_hyperparameters)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Accuracy:\u001b[39m\u001b[39m\"\u001b[39m, best_accuracy)\n",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\main.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m fold_recall \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(k_indices)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     train_x, train_y, test_x, test_y \u001b[39m=\u001b[39m prepare_data_for_fold(y, x, k_indices, k, selected_indices_categorical_train, all_categories)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(train_x)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWarning: NaN values detected in train_x! - althogh imputed pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\main.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train_x, train_y \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x[k_indices[(np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(k_indices)) \u001b[39m!=\u001b[39m k)]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     y[k_indices[(np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(k_indices)) \u001b[39m!=\u001b[39m k)]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#print(f\"Shape of train_x before preprocessing: {train_x.shape}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#print(f\"Shape of test_x before preprocessing: {test_x.shape}\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m train_x, test_x \u001b[39m=\u001b[39m apply_preprocessing(train_x, test_x, selected_indices_categorical_train, all_categories)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#print(f\"Shape of train_x after preprocessing: {train_x.shape}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#print(f\"Shape of test_x after preprocessing: {test_x.shape}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/main.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(train_x)\u001b[39m.\u001b[39many():\n",
      "File \u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\preprocess.py:102\u001b[0m, in \u001b[0;36mapply_preprocessing\u001b[1;34m(x_train, x_test, categorical_columns_indices, all_categories)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNaNs detected in after one hot \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[39m# 3. Apply Min-Max Scaling to all columns\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m x_train_imputed, scaling_params \u001b[39m=\u001b[39m min_max_scaling_array(x_train_imputed)\n\u001b[0;32m    103\u001b[0m x_test_imputed, _ \u001b[39m=\u001b[39m min_max_scaling_array(x_test_imputed, scaling_params)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(x_train_imputed)\u001b[39m.\u001b[39many():\n",
      "File \u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\preprocess.py:73\u001b[0m, in \u001b[0;36mmin_max_scaling_array\u001b[1;34m(data_array, scaling_parameters)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m         col_data \u001b[39m=\u001b[39m (col_data \u001b[39m-\u001b[39m col_min) \u001b[39m/\u001b[39m diff\n\u001b[1;32m---> 73\u001b[0m     data_array[:, col_idx] \u001b[39m=\u001b[39m col_data\n\u001b[0;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m data_array, scaling_parameters\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_fold = 5  # for 5-fold cross-validation\n",
    "seed = 42  \n",
    "k_indices = build_stratified_k_indices_with_seed(y_undersampled_train, k_fold, seed)\n",
    "model_funcs = [logistic_regression, reg_logistic_regression]\n",
    "best_model, best_hyperparameters, best_accuracy, best_f1 = grid_search_hyperparameters_weighted(y_undersampled_train, x_undersampled_train,  k_indices, model_funcs, selected_indices_categorical_train)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best F1 Score:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
