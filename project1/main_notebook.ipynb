{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3000000e+01 1.1000000e+01 1.1162015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [3.3000000e+01 1.2000000e+01 1.2152015e+07 ...           nan\n",
      "            nan           nan]\n",
      " [2.0000000e+01 1.0000000e+01 1.0202015e+07 ... 1.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [4.2000000e+01 6.0000000e+00 6.1820150e+06 ... 2.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [2.4000000e+01 1.1000000e+01 1.1062015e+07 ... 9.0000000e+00\n",
      "  9.0000000e+00 2.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "data_path=\"data/dataset_to_release\"\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path)\n",
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_p, x_test_p=apply_preprocessing(x_train, x_test, \n",
    "                                        correlation_tolerance=0.01, \n",
    "                                        outlier_coefficient=2.0, \n",
    "                                        polynomial_degree=1, \n",
    "                                        log_transform_columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_K_fold(y,k=5,seed=42):\n",
    "    no_of_test_labels=np.floor(y.shape[0]/k)\n",
    "    \n",
    "    unique_labels=np.unique(y)\n",
    "    label_ratio={};label_indexes={};label_count_p_fold={}\n",
    "\n",
    "    picked_count=0\n",
    "    for i,label in enumerate(unique_labels):\n",
    "        label_ratio[label]=y[y==label].shape[0]/y.shape[0]\n",
    "        label_indexes[label]=np.random.permutation(np.argwhere(y==label))\n",
    "        if i<len(unique_labels)-1:\n",
    "            label_count_p_fold[label]=np.floor(no_of_test_labels*label_ratio[label])\n",
    "            picked_count+=label_count_p_fold[label]\n",
    "        else:\n",
    "            label_count_p_fold[label]=no_of_test_labels-picked_count\n",
    "\n",
    "    folds=[]\n",
    "    for i in range(k):\n",
    "        index_arrs=[]\n",
    "        for label in unique_labels:\n",
    "            label_to_take=int(label_count_p_fold[label])\n",
    "            #print(i*label_to_take,(i+1)*label_to_take)\n",
    "            index_arrs.append(label_indexes[label][i*label_to_take:(i+1)*label_to_take].flatten())\n",
    "    \n",
    "        test_fold=np.random.permutation(np.concatenate(index_arrs))\n",
    "        train_fold=np.random.permutation(np.setdiff1d(np.indices(y.shape),test_fold,assume_unique=True))\n",
    "        #print(test_fold.shape,train_fold.shape)\n",
    "        folds.append((train_fold,test_fold))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def calculate_metrics(y_pred,y_true):\n",
    "    accuracy=y_pred[y_pred==y_true].shape[0]/y_pred.shape[0]\n",
    "    precision={};recall={}\n",
    "    for label in np.unique(y_true):\n",
    "        try:\n",
    "            precision[label]=y_pred[(y_pred==label) & (y_true==label)].shape[0]/y_pred[y_pred==label].shape[0]\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            recall[label]=y_pred[(y_pred==label) & (y_true==label)].shape[0]/y_true[y_true==label].shape[0]\n",
    "        except:\n",
    "            continue\n",
    "    return accuracy,precision,recall\n",
    "\n",
    "def calculate_confusion_mat(y_pred,y_true):\n",
    "    unique_labels=np.unique(y_true)\n",
    "    conf_matrix=np.zeros(len(unique_labels))\n",
    "    for i,pred_label in enumerate(unique_labels):\n",
    "        for j,true_label in enumerate(unique_labels):\n",
    "            conf_matrix[i,j]=y_pred[y_pred==pred_label & y_true==true_label].shape[0]\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=stratified_K_fold(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_classifier=LogisticRegression(penalty=\"l2\",class_weight=\"balanced\",C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.5092111478507322 Precision: {-1: 0.5101617863350716, 1: 0.4993960310612597} Recall: {-1: 0.9132086761406133, 1: 0.08987019439786349}\n",
      "##########################################\n",
      "Fold 2\n",
      "Accuracy: 0.5127310405778109 Precision: {-1: 0.514189731247493, 1: 0.4976704055220017} Recall: {-1: 0.9135586174129944, 1: 0.09026321554880912}\n",
      "##########################################\n",
      "Fold 3\n",
      "Accuracy: 0.5078549987048013 Precision: {-1: 0.5098609439764674, 1: 0.48714408973252804} Recall: {-1: 0.9112252822749268, 1: 0.08780988522193536}\n",
      "##########################################\n",
      "Fold 4\n",
      "Accuracy: 0.5135081597513219 Precision: {-1: 0.5149084102152695, 1: 0.4990509059534081} Recall: {-1: 0.9138856752988639, 1: 0.09061285875422985}\n",
      "##########################################\n",
      "Fold 5\n",
      "Accuracy: 0.5105520593658098 Precision: {-1: 0.5107634710522797, 1: 0.5083692838654013} Recall: {-1: 0.9147235774791224, 1: 0.09143956794338569}\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "for i,(train_fold,val_fold) in enumerate(folds):\n",
    "    print(\"Fold\",i+1)\n",
    "    x_train_fold=x_train_p[train_fold]\n",
    "    x_val_fold=x_train_p[val_fold]\n",
    "    \n",
    "    y_train_fold=y_train[train_fold]\n",
    "    y_val_fold=y_train[val_fold]\n",
    "\n",
    "    log_reg_classifier.fit(x_train_fold,y_train_fold)\n",
    "    #print(x_train_fold.shape)\n",
    "    #print(y_val_fold.shape)\n",
    "    y_pred=log_reg_classifier.predict(x_val_fold)\n",
    "    accuracy,precision,recall=*calculate_metrics(y_val_fold,y_pred),\n",
    "\n",
    "    #print(\"Val loss:\",calculate_logistic_loss(y_val_fold,x_val_fold,w))\n",
    "    print(\"Accuracy:\",accuracy,\"Precision:\",precision,\"Recall:\",recall)\n",
    "    print(\"##########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(train_fold,val_fold) in enumerate(folds):\n",
    "    print(\"Fold\",i+1)\n",
    "    x_train_fold=x_train_p[train_fold]\n",
    "    x_val_fold=x_train_p[val_fold]\n",
    "    \n",
    "    y_train_fold=y_train[train_fold]\n",
    "    y_val_fold=y_train[val_fold]\n",
    "\n",
    "    initial_w=np.zeros((x_train_fold.shape[1],))\n",
    "    #print(initial_w.shape)\n",
    "    \n",
    "    w,loss=reg_logistic_regression(y_train_fold,x_train_fold,lambda_=0.1 ,initial_w=initial_w, max_iters=100, gamma=0.3)\n",
    "    print(\"Train loss:\",loss)\n",
    "    \n",
    "    y_pred = sigmoid(x_val_fold.dot(w))\n",
    "    y_pred[y_pred>1/2]=1;y_pred[y_pred<1/2]=-1\n",
    "    accuracy,precision,recall=*calculate_metrics(y_val_fold,y_pred),\n",
    "\n",
    "    print(\"Val loss:\",calculate_logistic_loss(y_val_fold,x_val_fold,w))\n",
    "    print(\"Accuracy:\",accuracy,\"Precision:\",precision,\"Recall:\",recall)\n",
    "    print(\"##########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "1\n",
      "1\n",
      "Train loss: 3009347390860701.0\n",
      "Val loss: 69.07755278982135\n",
      "Accuracy: 0.08830207079403295 Precision: {1.0: 1.0} Recall: {1.0: 0.08830207079403295}\n",
      "##########################################\n",
      "Fold 2\n",
      "1\n",
      "1\n",
      "Train loss: 3009347346853776.0\n",
      "Val loss: 69.07755278982137\n",
      "Accuracy: 0.08830207079403295 Precision: {1.0: 1.0} Recall: {1.0: 0.08830207079403295}\n",
      "##########################################\n",
      "Fold 3\n",
      "1\n",
      "1\n",
      "Train loss: 3009347394243102.0\n",
      "Val loss: 69.07755278982138\n",
      "Accuracy: 0.08830207079403295 Precision: {1.0: 1.0} Recall: {1.0: 0.08830207079403295}\n",
      "##########################################\n",
      "Fold 4\n",
      "1\n",
      "1\n",
      "Train loss: 3009347370113477.0\n",
      "Val loss: 69.07755278982137\n",
      "Accuracy: 0.08830207079403295 Precision: {1.0: 1.0} Recall: {1.0: 0.08830207079403295}\n",
      "##########################################\n",
      "Fold 5\n",
      "1\n",
      "1\n",
      "Train loss: 3009347384193966.0\n",
      "Val loss: 69.07755278982137\n",
      "Accuracy: 0.08830207079403295 Precision: {1.0: 1.0} Recall: {1.0: 0.08830207079403295}\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "for i,(train_fold,val_fold) in enumerate(folds):\n",
    "    print(\"Fold\",i+1)\n",
    "    x_train_fold=x_train_p[train_fold]\n",
    "    x_val_fold=x_train_p[val_fold]\n",
    "    \n",
    "    y_train_fold=y_train[train_fold]\n",
    "    y_val_fold=y_train[val_fold]\n",
    "\n",
    "    initial_w=np.zeros((x_train_fold.shape[1],))\n",
    "    #print(initial_w.shape)\n",
    "    w,loss=reg_weighted_logistic_regression_balanced(y_train_fold,x_train_fold,lambda_=0.1 ,initial_w=initial_w, max_iters=100, gamma=0.3,class_weights={-1:1,1:1})\n",
    "    print(\"Train loss:\",loss)\n",
    "    y_pred = sigmoid(x_val_fold.dot(w))\n",
    "    y_pred[y_pred>1/2]=1;y_pred[y_pred<=1/2]=-1\n",
    "    accuracy,precision,recall=calculate_metrics(y_val_fold,y_pred)\n",
    "    total_samples = len(y_val_fold)\n",
    "    w1 = total_samples / np.sum(y_val_fold == 1)\n",
    "    w2 = total_samples / np.sum(y_val_fold == -1)\n",
    "    print(\"Val loss:\",calculate_weighted_logistic_loss(y_val_fold,x_val_fold,w,w1,w2))\n",
    "    print(\"Accuracy:\",accuracy,\"Precision:\",precision,\"Recall:\",recall)\n",
    "    print(\"##########################################\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
