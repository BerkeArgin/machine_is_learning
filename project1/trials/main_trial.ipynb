{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers_trials import *\n",
    "\n",
    "from implementations_trial import *\n",
    "from preprocess_trial import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"GENHLTH\", \"_RFHLTH\",\n",
    "    \"HLTHPLN1\", \"_HCVU651\",\n",
    "    \"BPHIGH4\", \"_RFHYPE5\",\n",
    "    \"BLOODCHO\", \"CHOLCHK\", \"_CHOLCHK\",\n",
    "    \"BLOODCHO\", \"TOLDHI2\", \"_RFCHOL\",\n",
    "    \"CVDINFR4\", \"CVDCRHD4\", \"_MICHD\",\n",
    "    \"ASTHMA3\", \"_LTASTH1\",\n",
    "    \"ASTHMA3\", \"ASTHNOW\", \"_CASTHM1\",\n",
    "    \"ASTHMA3\", \"ASTHNOW\", \"_ASTHMS1\",\n",
    "    \"HAVARTH3\", \"_DRDXAR1\",\n",
    "    \"MRACE1\", \"ORACE3\", \"MRACASC1\", \"_PRACE1\",\n",
    "    \"MRACE1\", \"MRACORG1\", \"MRACASC1\", \"_MRACE1\",\n",
    "    \"HISPANC3\", \"_HISPANC\",\n",
    "    \"MRACE1\", \"HISPANC3\", \"MRACORG1\", \"MRACASC1\", \"_MRACE1\", \"_HISPANC\", \"_RACE\",\n",
    "    \"HISPANC3\", \"MRACE1\", \"_RACE\", \"_RACEG21\",\n",
    "    \"HISPANC3\", \"MRACE1\", \"_RACE\", \"_RACEGR3\",\n",
    "    \"MRACE1\", \"HISPANC3\", \"_RACEGR3\", \"_RACE_G1\",\n",
    "    \"AGE\", \"_AGEG5YR\",\n",
    "    \"AGE\", \"_AGE65YR\",\n",
    "    \"AGE\", \"_IMPAGE\", \"_AGE80\",\n",
    "    \"AGE\", \"_IMPAGE\", \"_AGE_G\",\n",
    "    \"HEIGHT3\", \"HTIN4\",\n",
    "    \"HEIGHT3\", \"HTIN4\", \"HTM4\",\n",
    "    \"WEIGHT2\", \"WTKG3\",\n",
    "    \"SEX\", \"WEIGHT2\", \"HEIGHT3\", \"HTIN4\", \"HTM4\", \"WTKG3\", \"_BMI5\",\n",
    "    \"SEX\", \"WEIGHT2\", \"HEIGHT3\", \"HTIN4\", \"HTM4\", \"WTKG3\", \"_BMI5\", \"_BMI5CAT\",\n",
    "    \"SEX\", \"WEIGHT2\", \"HEIGHT3\", \"HTIN4\", \"HTM4\", \"WTKG3\", \"_BMI5\", \"_RFBMI5\",\n",
    "    \"CHILDREN\", \"_CHLDCNT\",\n",
    "    \"EDUCA\", \"_EDUCAG\",\n",
    "    \"INCOME2\", \"_INCOMG\",\n",
    "    \"SMOKE100\", \"SMOKDAY2\", \"_SMOKER3\",\n",
    "    \"SMOKE100\", \"SMOKDAY2\", \"_SMOKER3\", \"_RFSMOK3\",\n",
    "    \"ALCDAY5\", \"DRNKANY5\",\n",
    "    \"ALCDAY5\", \"DROCDY3_\",\n",
    "    \"ALCDAY5\", \"DRNK3GE5\", \"_RFBING5\",\n",
    "    \"ALCDAY5\", \"AVEDRNK\", \"DROCDY3_\", \"_DRNKWEK\",\n",
    "    \"SEX\", \"ALCDAY5\", \"AVEDRNK\", \"_DRNKWEK\", \"_RFDRHV5\",\n",
    "    \"FRUITJU1\", \"FTJUDA1_\",\n",
    "    \"FRUIT1\", \"FRUTDA1_\",\n",
    "    \"FVBEANS\", \"BEANDAY_\",\n",
    "    \"FVGREEN\", \"GRENDAY_\",\n",
    "    \"FVORANG\", \"ORNGDAY_\",\n",
    "    \"VEGETAB1\", \"VEGEDA1_\",\n",
    "    \"FRUITJU1\", \"FRUIT1\", \"FTJUDA1_\", \"FRUTDA1_\", \"_MISFRTN\",\n",
    "    \"VEGETAB1\", \"FVGREEN\", \"FVORANG\", \"FVBEANS\", \"GRENDAY_\", \"ORNGDAY_\", \"BEANDAY_\", \"VEGEDA1_\", \"_MISVEGN\",\n",
    "    \"FRUITJU1\", \"FRUIT1\", \"FTJUDA1_\", \"FRUTDA1_\", \"_MISFRTN\", \"_FRTRESP\",\n",
    "    \"VEGETAB1\", \"FVGREEN\", \"FVORANG\", \"FVBEANS\", \"GRENDAY_\", \"ORNGDAY_\", \"BEANDAY_\", \"VEGEDA1_\", \"_MISVEGN\", \"_VEGRESP\",\n",
    "    \"FRUITJU1\", \"FRUIT1\", \"FTJUDA1_\", \"FRUTDA1_\", \"_FRUTSUM\",\n",
    "    \"VEGETAB1\", \"FVGREEN\", \"FVORANG\", \"FVBEANS\", \"GRENDAY_\", \"ORNGDAY_\", \"BEANDAY_\", \"VEGEDA1_\", \"_VEGESUM\",\n",
    "    \"FRUITJU1\", \"FRUIT1\", \"VEGETAB1\", \"FVGREEN\", \"FVORANG\", \"FVBEANS\", \"FTJUDA1_\", \"FRUTDA1_\", \"VEGEDA1_\", \"GRENDAY_\", \"ORNGDAY_\", \"BEANDAY_\", \"_FRUTVEG\",\n",
    "    \"XPA1MIN_\", \"PA1MIN_\",\n",
    "    \"XPA1MIN_\", \"_PACAT1\",\n",
    "    \"PA1MIN_\", \"_METVL11\",\n",
    "    \"_METVL11\", \"_METVL21\",\n",
    "    \"PAQ650\", \"_RFPAVIG\",\n",
    "    \"PAQ655\", \"PAQ660\", \"_PAQ6C\",\n",
    "    \"PAQ660\", \"_PAINDX2\",\n",
    "    \"PAQ650\", \"PAQ665\", \"_PASTRNG\",\n",
    "    \"PAQ670\", \"_PAREC1\"\n",
    "]\n",
    "variables_set= set(variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/dataset_to_release\"\n",
    "x_train, x_test, y_train, train_ids, test_ids, col_names_train, col_names_test = load_csv_data(data_path, selected_cols=variables_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 299160, 1: 28975}\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the _MICHD labels\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices_with_seed(y, k_fold, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly partitions the indices of the dataset into k groups using a fixed seed.\n",
    "    Args:\n",
    "        y: labels, used for indexing\n",
    "        k_fold: number of groups after the partitioning\n",
    "        seed: the random seed value, default is 42\n",
    "    Returns:\n",
    "        k_indices: an array of k sub-indices that are randomly partitioned\n",
    "    \"\"\"\n",
    "    num_rows = y.shape[0]\n",
    "    interval = int(num_rows / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_rows)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred,y_true):\n",
    "    accuracy=y_pred[y_pred==y_true].shape[0]/y_pred.shape[0]\n",
    "    precision={};recall={}\n",
    "    for label in np.unique(y_true):\n",
    "        try:\n",
    "            precision[label]=y_pred[(y_pred==label) & (y_true==label)].shape[0]/y_pred[y_pred==label].shape[0]\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            recall[label]=y_pred[(y_pred==label) & (y_true==label)].shape[0]/y_true[y_true==label].shape[0]\n",
    "        except:\n",
    "            continue\n",
    "    return accuracy,precision,recall\n",
    "\n",
    "def prepare_data_for_fold(y, x, k_indices, k):\n",
    "    \"\"\"\n",
    "    Prepare the data for a given fold index.\n",
    "\n",
    "    Args:\n",
    "        y: Vector of labels\n",
    "        x: Feature matrix\n",
    "        k_indices: 2D array returned by build_k_indices()\n",
    "        k: scalar, the k-th fold\n",
    "        degree: Degree for polynomial expansion\n",
    "        high_skewness_cols: Columns that need log transform\n",
    "        high_residual_indices: Columns that need polynomial expansion\n",
    "\n",
    "    Returns:\n",
    "        train_x, train_y, test_x, test_y: Prepared data for the fold\n",
    "    \"\"\"\n",
    "    \n",
    "    test_x, test_y = x[k_indices[k]], y[k_indices[k]]\n",
    "    train_x, train_y = (\n",
    "        x[k_indices[(np.arange(len(k_indices)) != k)].reshape(-1)],\n",
    "        y[k_indices[(np.arange(len(k_indices)) != k)].reshape(-1)],\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    #print(f\"Shape of train_x before preprocessing: {train_x.shape}\")\n",
    "    #print(f\"Shape of test_x before preprocessing: {test_x.shape}\")\n",
    "    \n",
    "    #train_x, train_y = oversample_minority(train_x, train_y)\n",
    "    train_x, test_x = apply_preprocessing(train_x, test_x)\n",
    "\n",
    "    #print(f\"Shape of train_x after preprocessing: {train_x.shape}\")\n",
    "    #print(f\"Shape of test_x after preprocessing: {test_x.shape}\")\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "def predict(data, weights, is_logistic):\n",
    "        preds = data.dot(weights)\n",
    "        if is_logistic:\n",
    "            preds = np.where(sigmoid(preds) > 0.5, 1, -1)\n",
    "        else:\n",
    "            preds = np.where(preds >= 0, 1, -1)\n",
    "        return preds\n",
    "\n",
    "def train_and_evaluate(train_x, train_y, test_x, test_y, model_func, weights=None, \n",
    "                       lambda_=0.1, max_iters=1000, gamma=0.01):\n",
    "    \"\"\"\n",
    "    Train a model and evaluate it. Now adapted for weighted training and flexible arguments.\n",
    "\n",
    "    Args:\n",
    "        train_x, train_y: Training data\n",
    "        test_x, test_y: Testing data\n",
    "        model_func: The regression function to use\n",
    "        weights: Sample weights\n",
    "        lambda_: Regularization parameter (if applicable)\n",
    "        max_iters: Maximum number of iterations for iterative optimization methods, default 1000.\n",
    "        gamma: Learning rate for optimization methods, default 0.01.\n",
    "        **kwargs: Additional arguments for model_func\n",
    "\n",
    "    Returns:\n",
    "        Training and testing losses, accuracy, precision, and recall\n",
    "    \"\"\"\n",
    "\n",
    "    initial_w = np.zeros(train_x.shape[1])\n",
    "    #print(f\"Shape of train_x: {train_x.shape}\")\n",
    "    #print(f\"Shape of initial_w: {initial_w.shape}\")\n",
    "    \n",
    "    is_logistic = model_func in [logistic_regression, reg_logistic_regression, reg_logistic_regression_weighted, logistic_regression_weighted]\n",
    "    train_y_adjusted = (train_y + 1) / 2 if is_logistic else train_y\n",
    "    \n",
    "    # If weights are not provided, assume equal weights for all samples.\n",
    "    if weights is None:\n",
    "        weights = np.ones(train_y.shape[0])\n",
    "    \n",
    "    initial_w = np.zeros(train_x.shape[1])\n",
    "    \n",
    "    if model_func in [mean_squared_error_gd_weighted, mean_squared_error_sgd_weighted, logistic_regression_weighted]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, initial_w, max_iters, gamma, weights)\n",
    "    elif model_func in [reg_logistic_regression_weighted]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, lambda_, initial_w, max_iters, gamma, weights)\n",
    "    elif model_func in [least_squares_weighted, ridge_regression_weighted]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, lambda_, weights)\n",
    "    elif  model_func in [mean_squared_error_gd, mean_squared_error_sgd, logistic_regression]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, initial_w, max_iters, gamma)\n",
    "    elif model_func in  [reg_logistic_regression]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, lambda_, initial_w, max_iters, gamma)\n",
    "    elif model_func in [least_squares, ridge_regression]:\n",
    "        w, _ = model_func(train_y_adjusted, train_x, lambda_)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model selection\")\n",
    "    \n",
    "    \n",
    "    preds_train = predict(train_x, w, is_logistic)\n",
    "    loss_train = np.sqrt(np.mean((train_y - preds_train)** 2))\n",
    "    acc_train, precision_train, recall_train = calculate_metrics(preds_train, train_y)\n",
    "\n",
    "    preds_test = predict(test_x, w, is_logistic)\n",
    "    loss_test = np.sqrt(np.mean((test_y - preds_test) ** 2)) \n",
    "    acc_test, precision_test, recall_test = calculate_metrics(preds_test, test_y)\n",
    "\n",
    "    return loss_train, loss_test, acc_train, acc_test, precision_train, recall_train, precision_test, recall_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(precision, recall):\n",
    "    \"\"\"Compute the F1 score given precision and recall.\"\"\"\n",
    "    f1_scores = {}\n",
    "    for label in precision.keys():\n",
    "        if precision[label] + recall[label] != 0:\n",
    "            f1_scores[label] = 2 * (precision[label] * recall[label]) / (precision[label] + recall[label])\n",
    "        else:\n",
    "            f1_scores[label] = 0.0\n",
    "    return f1_scores\n",
    "\n",
    "def calculate_class_weights(y):\n",
    "    \"\"\"Calculate class weights based on inverse class frequencies.\"\"\"\n",
    "    class_weights = {}\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    total_samples = y.shape[0]\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        class_weights[cls] = total_samples / count\n",
    "        return class_weights\n",
    "\n",
    "def grid_search_hyperparameters_weighted(y, x, k_indices):\n",
    "    \"\"\"Perform grid search with progress tracking.\"\"\"\n",
    "    gammas = [0.001, 0.01, 0.1]\n",
    "    lambdas = [0.001, 0.01, 0.1, 1, 10]\n",
    "    max_iters_values = [100, 500, 1000, 2000]\n",
    "    model_funcs = [mean_squared_error_gd, mean_squared_error_sgd, least_squares, ridge_regression, \n",
    "                   logistic_regression, reg_logistic_regression,\n",
    "                   mean_squared_error_gd_weighted, mean_squared_error_sgd_weighted, \n",
    "                   least_squares_weighted, ridge_regression_weighted,\n",
    "                   logistic_regression_weighted, reg_logistic_regression_weighted]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_hyperparameters = None\n",
    "    \n",
    "    total_models = len(model_funcs)\n",
    "    for idx, model_func in enumerate(model_funcs):\n",
    "        print(f\"Evaluating Model {idx+1}/{total_models}: {model_func.__name__}\")\n",
    "        for gamma in gammas:\n",
    "            for lambda_ in lambdas:\n",
    "                for max_iters in max_iters_values:\n",
    "                    print(f\"Using hyperparameters: gamma={gamma}, lambda={lambda_}, max_iters={max_iters}\")\n",
    "                    avg_accuracy = 0\n",
    "                    avg_f1 = 0\n",
    "                    for k in range(len(k_indices)):\n",
    "                        print(f\"Processing Fold {k+1}/{len(k_indices)}\")\n",
    "                        train_x, train_y, test_x, test_y = prepare_data_for_fold(y, x, k_indices, k)\n",
    "                        weights = None\n",
    "                        if \"weighted\" in model_func.__name__:\n",
    "                            class_weights = calculate_class_weights(train_y)\n",
    "                            weights = np.array([class_weights[label] for label in train_y])\n",
    "                        _, _, _, acc_test, precision_train, recall_train, precision_test, recall_test = train_and_evaluate(\n",
    "                            train_x, train_y, test_x, test_y, model_func, weights, lambda_=lambda_, max_iters=max_iters, gamma=gamma)\n",
    "                        avg_accuracy += acc_test\n",
    "                        f1 = calculate_f1_score(precision_test, recall_test)\n",
    "                        avg_f1 += np.mean(list(f1.values()))\n",
    "                    avg_accuracy /= len(k_indices)\n",
    "                    avg_f1 /= len(k_indices)\n",
    "                    print(\"avg f1:\", avg_f1)\n",
    "                    if avg_accuracy > best_accuracy and avg_f1 > best_f1:\n",
    "                        best_accuracy = avg_accuracy\n",
    "                        best_f1 = avg_f1\n",
    "                        best_hyperparameters = {\"model_func\": model_func, \"gamma\": gamma, \"lambda\": lambda_, \"max_iters\": max_iters}\n",
    "                        \n",
    "    return best_hyperparameters, best_accuracy, best_f1\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model 1/12: mean_squared_error_gd\n",
      "Using hyperparameters: gamma=0.001, lambda=0.001, max_iters=100\n",
      "Processing Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zeyne\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\helpers_trials.py:19: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean((y - y_pred) ** 2) / 2\n",
      "c:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\implementations_trial.py:22: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - gamma * gradient_vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 2/5\n",
      "Processing Fold 3/5\n",
      "Processing Fold 4/5\n",
      "Processing Fold 5/5\n",
      "avg f1: 0.9538092018066905\n",
      "Using hyperparameters: gamma=0.001, lambda=0.001, max_iters=500\n",
      "Processing Fold 1/5\n",
      "Processing Fold 2/5\n",
      "Processing Fold 3/5\n",
      "Processing Fold 4/5\n",
      "Processing Fold 5/5\n",
      "avg f1: 0.9538092018066905\n",
      "Using hyperparameters: gamma=0.001, lambda=0.001, max_iters=1000\n",
      "Processing Fold 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\main_trial.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m seed \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m k_indices \u001b[39m=\u001b[39m build_k_indices_with_seed(y_train, k_fold, seed)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best_hyperparameters, best_accuracy, best_f1 \u001b[39m=\u001b[39m grid_search_hyperparameters_weighted(y_train, x_train, k_indices)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, best_hyperparameters)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Accuracy:\u001b[39m\u001b[39m\"\u001b[39m, best_accuracy)\n",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\main_trial.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     class_weights \u001b[39m=\u001b[39m calculate_class_weights(train_y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([class_weights[label] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m train_y])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m _, _, _, acc_test, precision_train, recall_train, precision_test, recall_test \u001b[39m=\u001b[39m train_and_evaluate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     train_x, train_y, test_x, test_y, model_func, weights, lambda_\u001b[39m=\u001b[39;49mlambda_, max_iters\u001b[39m=\u001b[39;49mmax_iters, gamma\u001b[39m=\u001b[39;49mgamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m avg_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m acc_test\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m f1 \u001b[39m=\u001b[39m calculate_f1_score(precision_test, recall_test)\n",
      "\u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\main_trial.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     w, _ \u001b[39m=\u001b[39m model_func(train_y_adjusted, train_x, lambda_, weights)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39melif\u001b[39;00m  model_func \u001b[39min\u001b[39;00m [mean_squared_error_gd, mean_squared_error_sgd, logistic_regression]:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     w, _ \u001b[39m=\u001b[39m model_func(train_y_adjusted, train_x, initial_w, max_iters, gamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39melif\u001b[39;00m model_func \u001b[39min\u001b[39;00m  [reg_logistic_regression]:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/zeyne/OneDrive/Masa%C3%BCst%C3%BC/project1-ML/Turco-ML/project1/trials/main_trial.ipynb#W6sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     w, _ \u001b[39m=\u001b[39m model_func(train_y_adjusted, train_x, lambda_, initial_w, max_iters, gamma)\n",
      "File \u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\implementations_trial.py:20\u001b[0m, in \u001b[0;36mmean_squared_error_gd\u001b[1;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m     17\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m iter_num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[0;32m     19\u001b[0m     \u001b[39m# compute loss and gradient\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     gradient_vector \u001b[39m=\u001b[39m calculate_gradient(y, tx, w)\n\u001b[0;32m     21\u001b[0m     \u001b[39m# update the weights\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m gamma \u001b[39m*\u001b[39m gradient_vector\n",
      "File \u001b[1;32mc:\\Users\\zeyne\\OneDrive\\Masaüstü\\project1-ML\\Turco-ML\\project1\\trials\\helpers_trials.py:32\u001b[0m, in \u001b[0;36mcalculate_gradient\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_gradient\u001b[39m(y, tx, w):\n\u001b[0;32m     23\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m    This function calculates the gradient at w and return gradient and error values.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m       The gradient of least squares (shape (D,)) and the error between observed and predicted outputs (shape (N,))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     error \u001b[39m=\u001b[39m y \u001b[39m-\u001b[39m tx\u001b[39m.\u001b[39;49mdot(w)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtx\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(error) \u001b[39m/\u001b[39m error\u001b[39m.\u001b[39msize\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_fold = 5  # for 5-fold cross-validation\n",
    "seed = 42  \n",
    "k_indices = build_k_indices_with_seed(y_train, k_fold, seed)\n",
    "\n",
    "best_hyperparameters, best_accuracy, best_f1 = grid_search_hyperparameters_weighted(y_train, x_train, k_indices)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best F1 Score:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
